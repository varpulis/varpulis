# Varpulis - Scenario 5: Anomaly Detection with Statistical Analysis
# Uses windowed aggregation and SASE+ temporal patterns to detect
# progressive degradation in sensor data.
#
# LINES OF CODE: ~50
# EQUIVALENT FLINK: Would require ~200+ lines with custom ProcessFunction

event SensorReading:
    sensor_id: str
    value: float
    unit: str
    location: str
    ts: timestamp

stream Sensors = SensorReading

# Statistical anomaly detection using windowed aggregation
# Detect when recent values deviate significantly from baseline
stream SensorStats = Sensors
    .partition_by(sensor_id)
    .window(1h, sliding: 5m)
    .aggregate(
        sensor_id: last(sensor_id),
        location: last(location),
        avg_value: avg(value),
        std_value: stddev(value),
        min_value: min(value),
        max_value: max(value),
        count: count()
    )

stream ProgressiveDegradation = SensorStats
    .where(std_value > avg_value * 0.3 and count > 10)
    .emit(
        alert_type: "PROGRESSIVE_DEGRADATION",
        severity: "warning",
        sensor_id: sensor_id,
        location: location,
        avg_value: avg_value,
        std_value: std_value,
        confidence: 0.85,
        recommendation: "Schedule preventive maintenance"
    )

# Detect anomalous peaks using SASE+ temporal patterns
# A normal reading followed by an abnormally high reading
stream AnomalousPeak = SensorReading as baseline
    -> SensorReading where sensor_id == baseline.sensor_id and value > baseline.value * 1.5 as spike
    .within(30m)
    .emit(
        alert_type: "ANOMALOUS_PEAK",
        severity: "warning",
        sensor_id: baseline.sensor_id,
        location: baseline.location,
        baseline_value: baseline.value,
        spike_value: spike.value,
        reason: "Significant value increase detected in recent readings"
    )
